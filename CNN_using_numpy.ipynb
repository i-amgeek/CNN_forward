{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Convolutional Neural Networks from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_one_step(image_slice, W, b):\n",
    "    s = W * image_slice      #image_slice.shape = (f,f)\n",
    "    Z = s.sum()\n",
    "    Z = np.squeeze(Z+b)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(images, W, b, hparameters):\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    m = images.shape[0]         # m denotes no of images\n",
    "    H,Wid,C = W.shape\n",
    "    \n",
    "    # Padding height and width\n",
    "    images_pad = np.pad(images, ((0,0),(pad,pad),(pad,pad)), 'constant', constant_values=(0))\n",
    "    \n",
    "    # Initiating zero matrix of size of Convolutional Block\n",
    "    Z = np.zeros((m,16,16,4))\n",
    "    \n",
    "    for i in range(m): \n",
    "        image_pad = images_pad[i]\n",
    "        for h in range(H):\n",
    "            for w in range(Wid):\n",
    "                for c in range(C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + 3\n",
    "                    hori_start = w * stride\n",
    "                    hori_end = hori_start + 3\n",
    "                    image_slice = image_pad[vert_start:vert_end, hori_start:hori_end]\n",
    "                    Z[i,h, w, c] = conv_one_step(image_slice,W[:,:,c],b[:,:,c])\n",
    "    cache = (images, W, b, hparameters)        # Will be used during backprop\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's initialize random weights for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For conv block\n",
    "W = np.random.randn(3,3,4)\n",
    "b = np.random.randn(1,1,4)\n",
    "\n",
    "# For first fully connected layer\n",
    "W_fc_1024 = np.random.randn(10,1024)\n",
    "b_fc_1024 = np.zeros((10,1))\n",
    "\n",
    "# For second fully connected layer\n",
    "W_10 = np.random.randn(1,10)\n",
    "b_10 = np.zeros((1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check our convolutional block and find A using relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16, 16, 4)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "no_of_images = m = 2\n",
    "images = np.random.randn(m,32,32)  # m images of (32,32)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv2D(images, W, b, hparameters)\n",
    "A = np.maximum(0,Z)\n",
    "assert(A.shape == Z.shape)\n",
    "activation_cache = Z        # Will be used for backpropogation\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Shape of A comes out to be (2,16,16,4) which is same as what we expected.\n",
    "\n",
    "## Fully connected layers\n",
    "* For first fully connected layer we just need to reshape it.\n",
    "* For second fc layer, we compute W*X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-12.89682204  13.37765949]]\n"
     ]
    }
   ],
   "source": [
    "fc_1024 = np.reshape(A, (m,-1))\n",
    "assert(fc_1024.shape[1] == 1024)\n",
    "fc_cache1 = fc_1024     # Will be used while backpropogation\n",
    "\n",
    "fc_10 = W_fc_1024.dot(fc_1024.T) + b_fc_1024\n",
    "fc_cache2 = fc_10       # Will be used while backpropogation\n",
    "\n",
    "y = W_10.dot(fc_10) + b_10\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating loss\n",
    "Now, we have our predicted output. Let's define MSE loss function and calculate loss comapring to some random Y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " def MSE_loss(Y, Y_test):\n",
    "     return np.square(Y - Y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.13788448\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.random.rand(m) * 10\n",
    "print(MSE_loss(y, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success\n",
    "**Now, we have successfully implemented forward propogation of Convolutional Neural Nets.**\n",
    "# Backward Propogation\n",
    "In backpropogation, we will find gradients of Weights, biases and layers using chain rule. It will take 5 steps:\n",
    "1. Find d_Y.\n",
    "2. Find d_w10, d_b10, d_fc10 (first fully connected).\n",
    "3. Find d_w1024, d_b1024, d_fc1024 (second fully connected).\n",
    "4. Find dZ (relu_backward).\n",
    "5. Find d_images, d_W, d_b (conv_backward).\n",
    "\n",
    "### Finding d_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_Y = 2 * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding d_w10, d_b10, d_fc10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_w10 = np.dot(d_Y, fc_10.T) / m\n",
    "d_b10 = np.sum(d_Y,axis=1,keepdims=True)/m\n",
    "d_fc10 = np.dot(W_10.T,d_Y)\n",
    "assert (d_fc10.shape == fc_10.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding d_w1024, d_b1024, d_fc1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_w1024 = np.dot(d_fc10, fc_1024) / m\n",
    "d_b1024 = np.sum(d_fc10,axis=1,keepdims=True)/m\n",
    "d_fc1024 = np.dot(W_fc_1024.T,d_fc10).T\n",
    "assert (d_fc1024.shape == fc_1024.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    dZ[Z <= 0] = 0\n",
    "    assert (dZ.shape == Z.shape)    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change shape of fc_1024 layer to size of conv_block i.e (m,16,16,4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fc = d_fc1024.reshape((m,16,16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16, 16, 4)\n"
     ]
    }
   ],
   "source": [
    "assert (d_fc.shape == A.shape) # Just to be sure d_fc is of correct dimensions\n",
    "dZ = relu_backward(d_fc, activation_cache)\n",
    "print(dZ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding d_images, d_W, d_b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    (images, W, b, hparameters) = cache\n",
    "\n",
    "    m = dZ.shape[0]\n",
    "    stride = hparameters['stride']\n",
    "    pad =hparameters['pad']\n",
    "    \n",
    "    # Initialize d_images, dW, db with the zeros\n",
    "    d_images = np.zeros((m,32,32))   \n",
    "    dW = np.zeros((3,3,4))\n",
    "    db = np.zeros((1,1,4))\n",
    "\n",
    "    images_pad = np.pad(images,((0,0),(pad,pad),(pad,pad)),'constant', constant_values=0)\n",
    "    d_images_pad = np.pad(d_images,((0,0),(pad,pad),(pad,pad)),'constant', constant_values=0)\n",
    "    \n",
    "    for i in range(m):        # for every image\n",
    "        \n",
    "        image_pad = images_pad[i,:,:]\n",
    "        d_image_pad = d_images_pad[i,:,:]\n",
    "        \n",
    "        for h in range(16):                  \n",
    "            for w in range(16):              \n",
    "                for c in range(4):           \n",
    "                    \n",
    "                    # Use the corners to define the slice from image_pad\n",
    "                    image_slice = images_pad[i,stride*h:stride*h+3,stride*w:stride*w+3]\n",
    "                    \n",
    "                    # Update gradients for the window and the filter's parameters\n",
    "                    d_image_pad[stride*h:stride*h+3,stride*w:stride*w+3] += W[:,:,c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,c] += image_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,c] += dZ[i, h, w, c]\n",
    "                    \n",
    "        d_images[i, :, :] = d_image_pad[pad:-pad,pad:-pad]\n",
    "    \n",
    "    assert(d_images.shape == (m, 32, 32))\n",
    "    return d_images, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_images, dW, db = conv_backward(dZ, cache_conv)\n",
    "assert (d_images.shape == images.shape == (m,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have dW, db, d_w10, d_b10, d_w1024 and d_b1024 and these gradients can be used to minimize our mse_loss function using any of the optimizer such as gradient descent, rmsprop or adam.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
