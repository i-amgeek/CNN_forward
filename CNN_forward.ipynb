{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_one_step(image_slice, W, b):\n",
    "    s = W * image_slice      #image_slice.shape = (f,f)\n",
    "    Z = s.sum()\n",
    "    Z = np.squeeze(Z+b)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(images, W, b, hparameters):\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    m = images.shape[0]         # m denotes no of images\n",
    "    H,Wid,C = W.shape\n",
    "    \n",
    "    # Padding height and width\n",
    "    images_pad = np.pad(images, ((0,0),(pad,pad),(pad,pad)), 'constant', constant_values=(0))\n",
    "    \n",
    "    # Initiating zero matrix of size of Convolutional Block\n",
    "    Z = np.zeros((m,16,16,4))\n",
    "    \n",
    "    for i in range(m): \n",
    "        image_pad = images_pad[i]\n",
    "        for h in range(H):\n",
    "            for w in range(Wid):\n",
    "                for c in range(C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + 3\n",
    "                    hori_start = w * stride\n",
    "                    hori_end = hori_start + 3\n",
    "                    image_slice = image_pad[vert_start:vert_end, hori_start:hori_end]\n",
    "                    Z[i,h, w, c] = conv_one_step(image_slice,W[:,:,c],b[:,:,c])\n",
    "    cache = (images, W, b, hparameters)        # Will be used during backprop\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's initialize random weights for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For conv block\n",
    "W = np.random.randn(3,3,4)\n",
    "b = np.random.randn(1,1,4)\n",
    "\n",
    "# For first fully connected layer\n",
    "W_fc_1024 = np.random.randn(10,1024)\n",
    "b_fc_1024 = np.zeros((10,1))\n",
    "\n",
    "# For second fully connected layer\n",
    "W_10 = np.random.randn(1,10)\n",
    "b_10 = np.zeros((1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check our convolutional block and find A using relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16, 16, 4)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "no_of_images = m = 2\n",
    "images = np.random.randn(m,32,32)  # m images of (32,32)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv2D(images, W, b, hparameters)\n",
    "A = np.maximum(0,Z)\n",
    "assert(A.shape == Z.shape)\n",
    "activation_cache = Z        # Will be used for backpropogation\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Shape of A comes out to be (2,16,16,4) which is same as what we expected.\n",
    "\n",
    "## Fully connected layers\n",
    "* For first fully connected layer we just need to reshape it.\n",
    "* For second fc layer, we compute W*X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-12.89682204  13.37765949]]\n"
     ]
    }
   ],
   "source": [
    "fc_1024 = np.reshape(A, (m,-1))\n",
    "assert(fc_1024.shape[1] == 1024)\n",
    "fc_cache1 = fc_1024     # Will be used while backpropogation\n",
    "\n",
    "fc_10 = W_fc_1024.dot(fc_1024.T) + b_fc_1024\n",
    "fc_cache2 = fc_10       # Will be used while backpropogation\n",
    "\n",
    "y = W_10.dot(fc_10) + b_10\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating loss\n",
    "Now, we have our predicted output. Let's define MSE loss function and calculate loss comapring to some random Y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " def MSE_loss(Y, Y_pred):\n",
    "     return np.square(Y - Y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.13788448\n"
     ]
    }
   ],
   "source": [
    "Y_pred = np.random.rand(m) * 10\n",
    "print(MSE_loss(y, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success\n",
    "**Now, we have successfully implemented forward propogation of Convolutional Neural Nets.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
